{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import keras\n",
    "import tensorflow\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n",
      "(2246,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 27595, 28842, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]),\n",
       "       list([1, 3267, 699, 3434, 2295, 56, 16784, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 19261, 49, 2295, 13415, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 13415, 30625, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12]),\n",
       "       list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 11733, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 13051, 71, 5, 160, 63, 11, 9, 26503, 81, 5, 102, 59, 11, 17, 12]),\n",
       "       ...,\n",
       "       list([1, 141, 3890, 387, 81, 8, 16, 1629, 10, 340, 1241, 850, 31, 56, 3890, 691, 9, 1241, 71, 9, 5985, 16338, 19170, 699, 19886, 13441, 18064, 699, 244, 5945, 4, 49, 8, 4, 656, 850, 33, 2993, 9, 2139, 340, 3371, 1493, 9, 17870, 22, 16964, 1094, 687, 83, 35, 15, 257, 6, 57, 9190, 7, 4, 5956, 654, 5, 17822, 6191, 1371, 4, 49, 8, 16, 369, 646, 6, 1076, 7, 124, 407, 17, 12]),\n",
       "       list([1, 53, 46, 957, 26, 14, 74, 132, 26, 39, 46, 258, 3614, 18, 14, 74, 134, 5131, 18, 88, 2321, 72, 11, 14, 1842, 32, 11, 123, 383, 89, 39, 46, 235, 10, 864, 728, 5, 258, 44, 11, 15, 22, 753, 9, 42, 92, 131, 728, 5, 69, 312, 11, 15, 22, 222, 10964, 3237, 383, 48, 39, 74, 235, 10, 864, 276, 5, 61, 32, 11, 15, 21, 4, 211, 5, 126, 1072, 42, 92, 131, 46, 19, 352, 11, 15, 22, 710, 220, 9, 42, 92, 131, 276, 5, 59, 61, 11, 15, 22, 10, 455, 7, 1172, 137, 336, 1325, 6, 1532, 142, 971, 6463, 43, 359, 5, 4, 326, 753, 364, 17, 12]),\n",
       "       list([1, 227, 2406, 91, 21969, 125, 2855, 21, 4, 3976, 76, 7, 4, 757, 481, 3976, 790, 5259, 5654, 9, 111, 149, 8, 7, 10, 76, 223, 51, 4, 417, 8, 1047, 91, 6917, 1688, 340, 7, 194, 9411, 6, 1894, 21, 127, 2151, 2394, 1456, 6, 3034, 4, 329, 433, 7, 65, 87, 1127, 10, 8219, 1475, 290, 9, 21, 567, 16, 1926, 24, 4, 76, 209, 30, 4033, 6655, 5654, 8, 4, 60, 8, 4, 966, 308, 40, 2575, 129, 15562, 295, 277, 1071, 9, 24, 286, 2114, 234, 222, 9, 4, 906, 3994, 8519, 114, 5758, 1752, 7, 4, 113, 17, 12])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=50000)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train,mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test,mode='binary')\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=46)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Dense(128,input_shape=(X_train[0].shape)))\n",
    "model.add(tf.keras.layers.Dense(512,activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(46,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               6400128   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                23598     \n",
      "=================================================================\n",
      "Total params: 6,623,534\n",
      "Trainable params: 6,622,510\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 170s 889ms/step - loss: 2.4085 - accuracy: 0.4598 - val_loss: 3.1541 - val_accuracy: 0.6848\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 10s 71ms/step - loss: 1.1535 - accuracy: 0.7320 - val_loss: 2.5715 - val_accuracy: 0.7306\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 7s 53ms/step - loss: 0.8763 - accuracy: 0.7976 - val_loss: 1.6869 - val_accuracy: 0.7600\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.6770 - accuracy: 0.8504 - val_loss: 1.1109 - val_accuracy: 0.7622\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 7s 53ms/step - loss: 0.5251 - accuracy: 0.8816 - val_loss: 0.9883 - val_accuracy: 0.7734\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 6s 43ms/step - loss: 0.3971 - accuracy: 0.9110 - val_loss: 0.9886 - val_accuracy: 0.7640\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 711s 5s/step - loss: 0.3451 - accuracy: 0.9264 - val_loss: 0.9742 - val_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 8s 56ms/step - loss: 0.3050 - accuracy: 0.9325 - val_loss: 0.9641 - val_accuracy: 0.7872\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 8s 56ms/step - loss: 0.2516 - accuracy: 0.9443 - val_loss: 0.9682 - val_accuracy: 0.7930\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 7s 53ms/step - loss: 0.2136 - accuracy: 0.9522 - val_loss: 0.9873 - val_accuracy: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe2453dca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data = (X_test,y_test), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 15ms/step - loss: 0.9873 - accuracy: 0.7867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9872742295265198, 0.7867319583892822]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count model for Converting sequence to matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(X_train,y_train),(X_test,y_test) = reuters.load_data()\n",
    "X_train = tokenizer.sequences_to_matrix(X_train,mode = 'count')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test,mode='count')\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=46)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=46)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Dense(128,input_shape=(X_train[0].shape)))\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(46,activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 14ms/step - loss: 3.8372 - accuracy: 4.5394e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.8368654251098633, 0.0017809439450502396]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-TDF mode for converting sequence to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "141/141 [==============================] - 52s 261ms/step - loss: 2.3330 - accuracy: 0.4673 - val_loss: 2.7090 - val_accuracy: 0.6291\n",
      "Epoch 2/10\n",
      "141/141 [==============================] - 7s 53ms/step - loss: 1.2667 - accuracy: 0.7093 - val_loss: 1.9228 - val_accuracy: 0.7119\n",
      "Epoch 3/10\n",
      "141/141 [==============================] - 7s 47ms/step - loss: 1.0035 - accuracy: 0.7777 - val_loss: 1.2961 - val_accuracy: 0.7324\n",
      "Epoch 4/10\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.8389 - accuracy: 0.8059 - val_loss: 1.1988 - val_accuracy: 0.7324\n",
      "Epoch 5/10\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.7055 - accuracy: 0.8288 - val_loss: 1.0253 - val_accuracy: 0.7556\n",
      "Epoch 6/10\n",
      "141/141 [==============================] - 7s 52ms/step - loss: 0.6010 - accuracy: 0.8591 - val_loss: 0.9879 - val_accuracy: 0.7809\n",
      "Epoch 7/10\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.5107 - accuracy: 0.8800 - val_loss: 1.0255 - val_accuracy: 0.7689\n",
      "Epoch 8/10\n",
      "141/141 [==============================] - 7s 47ms/step - loss: 0.4158 - accuracy: 0.9009 - val_loss: 1.0058 - val_accuracy: 0.7760\n",
      "Epoch 9/10\n",
      "141/141 [==============================] - 7s 51ms/step - loss: 0.3730 - accuracy: 0.9141 - val_loss: 1.0704 - val_accuracy: 0.7609\n",
      "Epoch 10/10\n",
      "141/141 [==============================] - 7s 49ms/step - loss: 0.3286 - accuracy: 0.9220 - val_loss: 1.1008 - val_accuracy: 0.7631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd4f39b940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=64,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 14ms/step - loss: 1.1008 - accuracy: 0.7631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1008374691009521, 0.7631344795227051]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
